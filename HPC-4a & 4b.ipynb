{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RhldTJoJWlUS","executionInfo":{"status":"ok","timestamp":1713949836866,"user_tz":-330,"elapsed":13,"user":{"displayName":"Nehal Ghewade","userId":"13662230505262185462"}},"outputId":"f4994ed9-6cd1-4efe-8f82-4ed698171a7f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Wed Apr 24 09:10:35 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   45C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"rbvDyqoSXvU8"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X1NmUrjGU2YS","executionInfo":{"status":"ok","timestamp":1713949848079,"user_tz":-330,"elapsed":7,"user":{"displayName":"Nehal Ghewade","userId":"13662230505262185462"}},"outputId":"38d6d373-b79d-44c4-da3b-4afca32c3e77"},"outputs":[{"output_type":"stream","name":"stdout","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2023 NVIDIA Corporation\n","Built on Tue_Aug_15_22:02:13_PDT_2023\n","Cuda compilation tools, release 12.2, V12.2.140\n","Build cuda_12.2.r12.2/compiler.33191640_0\n"]}],"source":["!nvcc --version"]},{"cell_type":"code","source":["!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mpWKQ74oU-XR","executionInfo":{"status":"ok","timestamp":1713949869090,"user_tz":-330,"elapsed":15389,"user":{"displayName":"Nehal Ghewade","userId":"13662230505262185462"}},"outputId":"e80f1fbd-0a4a-4f06-e30f-347f5baddfd9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n","  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-8x8_dz2v\n","  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-8x8_dz2v\n","  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 5741c522547756ac4bb7a16df32106a15efb8a57\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: nvcc4jupyter\n","  Building wheel for nvcc4jupyter (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for nvcc4jupyter: filename=nvcc4jupyter-1.2.1-py3-none-any.whl size=10741 sha256=1c43b610d84440f376c57bb0b3d20f87e2433fdb6f06eb98d5fd7c81c461a971\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-glx69gq3/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n","Successfully built nvcc4jupyter\n","Installing collected packages: nvcc4jupyter\n","Successfully installed nvcc4jupyter-1.2.1\n"]}]},{"cell_type":"code","source":["%load_ext nvcc4jupyter"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P4AbIwhFVcgy","executionInfo":{"status":"ok","timestamp":1713949874297,"user_tz":-330,"elapsed":6,"user":{"displayName":"Nehal Ghewade","userId":"13662230505262185462"}},"outputId":"7afc67d6-75cc-47c9-f7fe-8ae465e7388f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Detected platform \"Colab\". Running its setup...\n","Source files will be saved in \"/tmp/tmp_v4wsfkg\".\n"]}]},{"cell_type":"code","source":["%%cuda\n","#include <stdio.h>\n","#include <stdlib.h>\n","#include <cuda_runtime.h>\n","\n","#define N 1000000\n","\n","// CUDA kernel for vector addition\n","__global__ void vectorAdd(int *a, int *b, int *c, int n) {\n","    int i = blockDim.x * blockIdx.x + threadIdx.x;\n","    if (i < n) {\n","        c[i] = a[i] + b[i];\n","    }\n","}\n","int main() {\n","\n","    int *h_a, *h_b, *h_c;\n","    int *d_a, *d_b, *d_c;\n","    int size = N * sizeof(int);\n","\n","    h_a = (int *)malloc(size);\n","    h_b = (int *)malloc(size);\n","    h_c = (int *)malloc(size);\n","\n","    for (int i = 0; i < N; ++i) {\n","        h_a[i] = i;\n","        h_b[i] = i * 2;\n","    }\n","\n","    cudaMalloc((void **)&d_a, size);\n","    cudaMalloc((void **)&d_b, size);\n","    cudaMalloc((void **)&d_c, size);\n","\n","    cudaMemcpy(d_a, h_a, size, cudaMemcpyHostToDevice);\n","    cudaMemcpy(d_b, h_b, size, cudaMemcpyHostToDevice);\n","\n","    dim3 dimGrid((N + 255) / 256, 1, 1);\n","    dim3 dimBlock(256, 1, 1);\n","\n","    vectorAdd<<<dimGrid, dimBlock>>>(d_a, d_b, d_c, N);\n","\n","    cudaMemcpy(h_c, d_c, size, cudaMemcpyDeviceToHost);\n","\n","    for (int i = 0; i < 10; ++i) {\n","        printf(\"%d + %d = %d\\n\", h_a[i], h_b[i], h_c[i]);\n","    }\n","\n","    cudaFree(d_a);\n","    cudaFree(d_b);\n","    cudaFree(d_c);\n","\n","    free(h_a);\n","    free(h_b);\n","    free(h_c);\n","    return 0;\n","}\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R6E0tEo2Xx96","executionInfo":{"status":"ok","timestamp":1713597992608,"user_tz":-330,"elapsed":1650,"user":{"displayName":"Nehal Ghewade","userId":"13662230505262185462"}},"outputId":"2094d77a-9340-46c6-954c-46d76957e753"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0 + 0 = 0\n","1 + 2 = 3\n","2 + 4 = 6\n","3 + 6 = 9\n","4 + 8 = 12\n","5 + 10 = 15\n","6 + 12 = 18\n","7 + 14 = 21\n","8 + 16 = 24\n","9 + 18 = 27\n","\n"]}]},{"cell_type":"code","source":["%%cuda\n","#include <stdio.h>\n","#include <stdlib.h>\n","#include <cuda_runtime.h>\n","\n","#define N 32 // Matrix size\n","\n","// CUDA kernel for matrix multiplication\n","__global__ void matrixMul(int *a, int *b, int *c, int n) {\n","    int row = blockIdx.y * blockDim.y + threadIdx.y;\n","    int col = blockIdx.x * blockDim.x + threadIdx.x;\n","\n","    if (row < n && col < n) {\n","        int sum = 0;\n","        // Compute dot product of row of matrix A and column of matrix B\n","        for (int i = 0; i < n; ++i) {\n","            sum += a[row * n + i] * b[i * n + col];\n","        }\n","        // Store result in the corresponding cell of matrix C\n","        c[row * n + col] = sum;\n","    }\n","}\n","\n","int main() {\n","    // Matrix dimensions\n","    int size = N * N * sizeof(int);\n","\n","    // Host matrices\n","    int *h_a, *h_b, *h_c;\n","\n","    // Device matrices\n","    int *d_a, *d_b, *d_c;\n","\n","    // Allocate memory for host matrices\n","    h_a = (int *)malloc(size);\n","    h_b = (int *)malloc(size);\n","    h_c = (int *)malloc(size);\n","\n","    // Initialize host matrices\n","    for (int i = 0; i < N * N; ++i) {\n","        h_a[i] = i;\n","        h_b[i] = i * 2;\n","    }\n","\n","    // Allocate memory for device matrices\n","    cudaMalloc((void **)&d_a, size);\n","    cudaMalloc((void **)&d_b, size);\n","    cudaMalloc((void **)&d_c, size);\n","\n","    // Copy host matrices to device\n","    cudaMemcpy(d_a, h_a, size, cudaMemcpyHostToDevice);\n","    cudaMemcpy(d_b, h_b, size, cudaMemcpyHostToDevice);\n","\n","    // Define grid and block size\n","    dim3 dimGrid(ceil(N / 16.0), ceil(N / 16.0), 1);\n","    dim3 dimBlock(16, 16, 1);\n","\n","    // Print input matrices\n","    printf(\"Matrix A (Input):\\n\");\n","    for (int i = 0; i < 4; ++i) {\n","        for (int j = 0; j < 4; ++j) {\n","            printf(\"%d \", h_a[i * N + j]);\n","        }\n","        printf(\"\\n\");\n","    }\n","\n","    printf(\"\\nMatrix B (Input):\\n\");\n","    for (int i = 0; i < 4; ++i) {\n","        for (int j = 0; j < 4; ++j) {\n","            printf(\"%d \", h_b[i * N + j]);\n","        }\n","        printf(\"\\n\");\n","    }\n","\n","    // Launch matrixMul kernel on GPU\n","    matrixMul<<<dimGrid, dimBlock>>>(d_a, d_b, d_c, N);\n","\n","    // Copy result from device to host\n","    cudaMemcpy(h_c, d_c, size, cudaMemcpyDeviceToHost);\n","\n","    // Print result matrix\n","    printf(\"\\nResult Matrix (Output):\\n\");\n","    for (int i = 0; i < 4; ++i) {\n","        for (int j = 0; j < 4; ++j) {\n","            printf(\"%d \", h_c[i * N + j]);\n","        }\n","        printf(\"\\n\");\n","    }\n","\n","    // Free device memory\n","    cudaFree(d_a);\n","    cudaFree(d_b);\n","    cudaFree(d_c);\n","\n","    // Free host memory\n","    free(h_a);\n","    free(h_b);\n","    free(h_c);\n","\n","    return 0;\n","}\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cLBY20sVXwwU","executionInfo":{"status":"ok","timestamp":1713949892720,"user_tz":-330,"elapsed":4192,"user":{"displayName":"Nehal Ghewade","userId":"13662230505262185462"}},"outputId":"412cf9be-5fa8-4880-a92f-f46276ca0483"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Matrix A (Input):\n","0 1 2 3 \n","32 33 34 35 \n","64 65 66 67 \n","96 97 98 99 \n","\n","Matrix B (Input):\n","0 2 4 6 \n","64 66 68 70 \n","128 130 132 134 \n","192 194 196 198 \n","\n","Result Matrix (Output):\n","666624 667616 668608 669600 \n","1682432 1685472 1688512 1691552 \n","2698240 2703328 2708416 2713504 \n","3714048 3721184 3728320 3735456 \n","\n"]}]}]}